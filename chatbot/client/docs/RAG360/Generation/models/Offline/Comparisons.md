| **Model**              | **Developed by**               | **Parameter size**  | **License**                                         | **Context length**                    | **Memory requirements**                                                                                                       |
| ---------------------- | ------------------------------ | ------------------- | --------------------------------------------------- | ------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| **Qwen 2**             | Alibaba Group                  | 0.5B, 1.5B, 7B, 72B | Expect 72B Apache License. 72B uses Qianwen License | 0.5B, 1.5B - 32K; 7B, 72B – 128K      |                                                                                                                               |
| **Llama 3**            | Meta                           | 8B, 70B             | META LLAMA 3 COMMUNITY LICENSE                      | 8K                                    |                                                                                                                               |
| **Llama 2**            | Meta                           | 7B, 13B, 70B        | META license                                        | 4K                                    | 7B – 8GB of RAM; 13B – 16GB of RAM; 70B – 64GB of RAM                                                                         |
| **LLama 3 - Gradient** | Gradient                       | 8B, 70B             |                                                     | 8K to > 1040K                         | Using a 256K context window requires at least 64GB of memory. Using a 1M+ context window requires significantly more (100GB+) |
| **Phi 3**              | Microsoft                      | 3B, 14B             | MIT license                                         | Phi 3 mini - 4K and Phi 3 medium 128K |                                                                                                                               |
| **Falcon 2 - 11B**     | Technical Innovation Institute | 11B                 | TII Falcon License 2.0                              | 8K                                    |                                                                                                                               |
| **Gemma 2**            | Google and its DeepMind team   | 9B, 27B             | Google’s usage license                              | 8K                                    |                                                                                                                               |
| **Mistral**            | Mistral AI                     | 2B, 7B              | Apache version 2.0                                  | 32K                                   |                                                                                                                               |

:::info[Qwen2 vs Llama3]
[Reference Link](https://aimlapi.com/comparisons/qwen-2-vs-llama-3-comparison#:~:text=Qwen%202%20output&text=LLama%203%20gave%20the%20answer,better%20in%20straight%20language%20tasks)
:::
